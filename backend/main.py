from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from typing import List, Dict, Any, Optional
import logging
from datetime import datetime
from contextlib import asynccontextmanager

from services.openai_service import OpenAIService
from services.milvus_service import MilvusService
from services.memory_service import MemoryService
from services.time_service import TimeService
from services.emotion_service import EmotionAnalyzer, EventClassifier
from models.chat_models import ChatRequest, ChatResponse, Message, HealthResponse, MemoryStatsResponse

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€æœåŠ¡å®ä¾‹
openai_service = None
milvus_service = None
memory_service = None
time_service = None
emotion_analyzer = None
event_classifier = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global openai_service, milvus_service, memory_service, time_service, emotion_analyzer, event_classifier
    
    try:
        logger.info("æ­£åœ¨åˆå§‹åŒ–å¢å¼ºæœåŠ¡...")
        
        # åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡
        openai_service = OpenAIService()
        logger.info("âœ“ OpenAI æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        milvus_service = MilvusService()
        await milvus_service.initialize()
        logger.info("âœ“ Milvus æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        memory_service = MemoryService()
        logger.info(f"âœ“ SuperMemory æœåŠ¡åˆå§‹åŒ–{'æˆåŠŸ' if memory_service.enabled else 'å¤±è´¥ï¼ˆå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰'}")
        
        time_service = TimeService()
        logger.info("âœ“ æ—¶é—´æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        emotion_analyzer = EmotionAnalyzer()
        event_classifier = EventClassifier()
        logger.info("âœ“ æƒ…ç»ªåˆ†æå’Œäº‹ä»¶åˆ†ç±»æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        
        logger.info("ğŸš€ æ‰€æœ‰å¢å¼ºæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        yield
        
    except Exception as e:
        logger.error(f"æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    finally:
        logger.info("åº”ç”¨å…³é—­ï¼Œæ¸…ç†èµ„æº...")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Project Yuzuriha - Enhanced AI Chat API",
    description="åŸºäºOpenAIã€Milvuså’ŒSuperMemoryçš„å¢å¼ºAIèŠå¤©API",
    version="2.0.0",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.post("/api/chat", response_model=ChatResponse)
async def enhanced_chat(request: ChatRequest, background_tasks: BackgroundTasks):
    """å¢å¼ºçš„èŠå¤©å¤„ç† - æ·»åŠ æ›´å¥½çš„é”™è¯¯å¤„ç†"""
    try:
        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message[:50]}...")
        
        # éªŒè¯è¾“å…¥
        if not request.message or not request.message.strip():
            raise HTTPException(status_code=400, detail="æ¶ˆæ¯å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # 1. åˆ›å»ºæŸ¥è¯¢åµŒå…¥
        try:
            query_embedding = await openai_service.create_embedding(request.message)
        except Exception as e:
            logger.error(f"åˆ›å»ºåµŒå…¥å¤±è´¥: {e}")
            query_embedding = [0.0] * 1536  # ä½¿ç”¨é»˜è®¤åµŒå…¥
        
        # 2. åˆ†æç”¨æˆ·æ¶ˆæ¯
        try:
            user_emotion = emotion_analyzer.analyze_emotion(request.message)
            user_category, user_confidence = event_classifier.classify_event(request.message)
        except Exception as e:
            logger.error(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            user_emotion = {'emotion_weight': 0.5}
            user_category, user_confidence = 'general', 0.5
        
        # 3. ä»SuperMemoryæ£€ç´¢ç›¸å…³è®°å¿†
        supermemory_memories = []
        try:
            supermemory_memories = await memory_service.retrieve_relevant_memories(
                request.message, limit=3
            )
            logger.info(f"ä»SuperMemoryæ£€ç´¢åˆ° {len(supermemory_memories)} ä¸ªè®°å¿†")
        except Exception as e:
            logger.warning(f"SuperMemoryæ£€ç´¢å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨Milvus: {e}")

        # 4. ä»Milvusæœç´¢å‘é‡ç›¸ä¼¼çš„è®°å¿†
        milvus_memories = []
        try:
            milvus_memories = await milvus_service.search_memories(
                query_embedding, 
                limit=3,
                emotion_weight_threshold=0.3 if user_emotion.get('emotion_weight', 0) > 0.5 else 0.0
            )
            logger.info(f"ä»Milvusæ£€ç´¢åˆ° {len(milvus_memories)} ä¸ªè®°å¿†")
        except Exception as e:
            logger.error(f"Milvusæœç´¢å¤±è´¥: {e}")
        
        # 5. åˆå¹¶è®°å¿†
        all_memories = supermemory_memories + milvus_memories
        
        # 6. è½¬æ¢å†å²æ¶ˆæ¯æ ¼å¼
        conversation_history = []
        try:
            conversation_history = [
                {'role': msg.role, 'content': msg.content} 
                for msg in (request.history or [])
                if msg.content and msg.content.strip()
            ]
        except Exception as e:
            logger.error(f"å¤„ç†å†å²æ¶ˆæ¯å¤±è´¥: {e}")
        
        # 7. ç”ŸæˆAIå›å¤
        try:
            response = await openai_service.generate_response(
                request.message,
                memories=all_memories,
                conversation_history=conversation_history
            )
            
            # éªŒè¯å“åº”
            if not response or not response.strip():
                response = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›å¤ã€‚è¯·ç¨åå†è¯•ã€‚"
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}")
            response = "æŠ±æ­‰ï¼Œå‘é€æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å¹¶é‡è¯•ã€‚"
        
        # 8. åå°å­˜å‚¨è®°å¿†
        try:
            background_tasks.add_task(
                store_conversation_memories,
                request.message,
                response,
                query_embedding,
                user_emotion,
                user_category,
                user_confidence
            )
        except Exception as e:
            logger.error(f"æ·»åŠ åå°ä»»åŠ¡å¤±è´¥: {e}")
        
        logger.info("âœ“ èŠå¤©è¯·æ±‚å¤„ç†æˆåŠŸ")
        
        # æ„å»ºè¿”å›çš„è®°å¿†åˆ—è¡¨
        response_memories = []
        try:
            response_memories = [
                {
                    "text": m.get("content", ""),
                    "score": m.get("relevance_score", 0.0),
                    "source": "supermemory",
                    "timestamp": m.get("timestamp", 0)
                } for m in supermemory_memories
            ] + [
                {
                    "text": m.get("text", ""),
                    "score": m.get("score", 0.0),
                    "source": "milvus",
                    "timestamp": m.get("timestamp", 0)
                } for m in milvus_memories
            ]
        except Exception as e:
            logger.error(f"æ„å»ºè®°å¿†å“åº”å¤±è´¥: {e}")
            response_memories = []
        
        return ChatResponse(
            response=response,
            memories=response_memories
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ èŠå¤©å¤„ç†é”™è¯¯: {e}")
        return ChatResponse(
            response="æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ã€‚è¯·ç¨åå†è¯•ã€‚",
            memories=[]
        )

async def store_conversation_memories(
    user_message: str,
    ai_response: str,
    query_embedding: List[float],
    user_emotion: Dict[str, float],
    user_category: str,
    user_confidence: float
):
    """åå°ä»»åŠ¡ï¼šå­˜å‚¨å¯¹è¯è®°å¿† - æ”¹è¿›é”™è¯¯å¤„ç†"""
    try:
        # 1. å­˜å‚¨åˆ°SuperMemory
        supermemory_success = False
        try:
            supermemory_success = await memory_service.store_conversation_memory(
                user_message, ai_response
            )
        except Exception as e:
            logger.error(f"SuperMemoryå­˜å‚¨å¤±è´¥: {e}")
        
        logger.info(f"SuperMemoryå­˜å‚¨: {'æˆåŠŸ' if supermemory_success else 'å¤±è´¥'}")
        
        # 2. åˆ†æAIå›å¤
        try:
            ai_emotion = emotion_analyzer.analyze_emotion(ai_response)
            ai_category, ai_confidence = event_classifier.classify_event(ai_response)
        except Exception as e:
            logger.error(f"AIå›å¤åˆ†æå¤±è´¥: {e}")
            ai_emotion = {'emotion_weight': 0.5}
            ai_category, ai_confidence = 'general', 0.5
        
        # 3. ç¡®å®šäº¤äº’ç±»å‹
        try:
            interaction_type = memory_service._determine_interaction_type(user_category, ai_category)
        except Exception as e:
            logger.error(f"ç¡®å®šäº¤äº’ç±»å‹å¤±è´¥: {e}")
            interaction_type = 'general_conversation'
        
        # 4. å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ°Milvus
        milvus_user_success = False
        try:
            milvus_user_success = await milvus_service.store_memory(
                text=f"ç”¨æˆ·: {user_message}",
                embedding=query_embedding,
                emotion_weight=user_emotion.get('emotion_weight', 0.5),
                event_category=user_category,
                interaction_type=interaction_type
            )
        except Exception as e:
            logger.error(f"Milvusç”¨æˆ·æ¶ˆæ¯å­˜å‚¨å¤±è´¥: {e}")
        
        # 5. ä¸ºAIå›å¤åˆ›å»ºåµŒå…¥å¹¶å­˜å‚¨
        milvus_ai_success = False
        try:
            ai_embedding = await openai_service.create_embedding(ai_response)
            milvus_ai_success = await milvus_service.store_memory(
                text=f"åŠ©æ‰‹: {ai_response}",
                embedding=ai_embedding,
                emotion_weight=ai_emotion.get('emotion_weight', 0.5),
                event_category=ai_category,
                interaction_type=interaction_type
            )
        except Exception as e:
            logger.error(f"Milvus AIå›å¤å­˜å‚¨å¤±è´¥: {e}")
        
        logger.info(f"âœ“ è®°å¿†å­˜å‚¨å®Œæˆ - SuperMemory: {'âœ“' if supermemory_success else 'âœ—'}, Milvusç”¨æˆ·: {'âœ“' if milvus_user_success else 'âœ—'}, MilvusAI: {'âœ“' if milvus_ai_success else 'âœ—'}")
        
    except Exception as e:
        logger.error(f"å­˜å‚¨å¯¹è¯è®°å¿†æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# å…¶ä½™è·¯ç”±ä¿æŒä¸å˜...
@app.get("/health", response_model=HealthResponse)
async def enhanced_health_check():
    """å¢å¼ºçš„å¥åº·æ£€æŸ¥"""
    try:
        time_info = time_service.get_time_context()
        model_info = openai_service.get_model_info()
        supermemory_info = memory_service.get_client_info()
        
        services_status = {
            "openai": openai_service is not None,
            "milvus": milvus_service is not None and milvus_service.client is not None,
            "supermemory": memory_service is not None and memory_service.enabled,
            "supermemory_client": supermemory_info['client_available'],
            "time_service": time_service is not None,
            "emotion_analyzer": emotion_analyzer is not None,
            "event_classifier": event_classifier is not None
        }
        
        overall_status = "healthy" if all([
            services_status["openai"],
            services_status["milvus"],
            services_status["time_service"],
            services_status["emotion_analyzer"],
            services_status["event_classifier"]
        ]) else "unhealthy"
        
        return HealthResponse(
            status=overall_status,
            timestamp=datetime.now().isoformat(),
            services=services_status,
            time_info=time_info,
            model_info=model_info,
            supermemory_info=supermemory_info
        )
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return HealthResponse(
            status="error",
            timestamp=datetime.now().isoformat(),
            services={},
            time_info={},
            model_info={},
            supermemory_info={}
        )

@app.get("/api/memories/stats", response_model=MemoryStatsResponse)
async def get_memory_stats():
    """è·å–è®°å¿†ç»Ÿè®¡"""
    try:
        milvus_stats = await milvus_service.get_memory_stats()
        return MemoryStatsResponse(**milvus_stats)
    except Exception as e:
        logger.error(f"è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è®°å¿†ç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Project Yuzuriha - Enhanced AI Chat API",
        "version": "2.0.0",
        "status": "running",
        "docs": "/docs"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)